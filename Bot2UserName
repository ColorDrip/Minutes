import os
import pandas as pd
import numpy as np
import re
import random
from datetime import datetime
import spacy
from spacy.matcher import PhraseMatcher
import en_core_web_md  # Medium-sized English model

class AdvancedFAQSystem:
    def __init__(self, faq_path="faq_knowledge.xlsx", log_path="conversation_log.xlsx"):
        self.faq_path = faq_path
        self.log_path = log_path
        
        # Load NLP model
        self.nlp = en_core_web_md.load()
        
        # Initialize files
        self.initialize_files()
        
        # Load data
        self.faqs = pd.read_excel(self.faq_path)
        self.logs = pd.read_excel(self.log_path) if os.path.exists(self.log_path) else pd.DataFrame()
        
        # Prepare NLP components
        self.prepare_nlp_models()
    
    def initialize_files(self):
        """Create template files if they don't exist"""
        # FAQ knowledge base
        if not os.path.exists(self.faq_path) or pd.read_excel(self.faq_path).empty:
            faq_template = pd.DataFrame({
                'Question': [
                    'What is your return policy?',
                    'How do I reset my password?',
                    'Do you ship internationally?'
                ],
                'Answer': [
                    'We offer a 30-day return policy on all unused items',
                    'Click "Forgot Password" on the login page',
                    'Yes, we ship to over 50 countries'
                ],
                'Category': ['Policy', 'Account', 'Shipping'],
                'Keywords': ['return, refund, exchange', 'password, login, access', 'ship, international, global'],
                'Last Used': [np.nan] * 3,
                'Use Count': [0] * 3
            })
            faq_template.to_excel(self.faq_path, index=False)
        
        # Conversation log
        if not os.path.exists(self.log_path):
            log_template = pd.DataFrame(columns=[
                'Timestamp', 'User Input', 'System Response', 
                'Matched Question', 'Confidence', 'Method'
            ])
            log_template.to_excel(self.log_path, index=False)
    
    def prepare_nlp_models(self):
        """Prepare NLP models for matching"""
        # Create phrase matcher for keywords
        self.keyword_matcher = PhraseMatcher(self.nlp.vocab, attr="LOWER")
        
        # Create document vectors for semantic matching
        self.question_docs = []
        self.question_vectors = []
        
        for _, row in self.faqs.iterrows():
            # Process question
            doc = self.nlp(row['Question'])
            self.question_docs.append(doc)
            self.question_vectors.append(doc.vector)
            
            # Add keywords to matcher
            if pd.notna(row['Keywords']):
                for keyword in row['Keywords'].split(','):
                    keyword = keyword.strip()
                    if keyword:
                        self.keyword_matcher.add(keyword, [self.nlp(keyword)])
        
        self.question_vectors = np.array(self.question_vectors)
    
    def find_best_match(self, query):
        """Find best match using combined NLP techniques"""
        query_doc = self.nlp(query)
        
        # Method 1: Semantic similarity
        query_vector = query_doc.vector.reshape(1, -1)
        similarities = np.dot(self.question_vectors, query_vector.T).flatten()
        semantic_index = np.argmax(similarities)
        semantic_score = similarities[semantic_index]
        
        # Method 2: Keyword matching
        keyword_matches = self.keyword_matcher(query_doc)
        keyword_scores = {match_id: 0 for match_id in range(len(self.faqs))}
        
        for match_id, start, end in keyword_matches:
            keyword_scores[match_id] += 1
        
        if keyword_scores:
            keyword_index = max(keyword_scores, key=keyword_scores.get)
            keyword_score = keyword_scores[keyword_index] / 3  # Normalize
        else:
            keyword_index = semantic_index
            keyword_score = 0
        
        # Method 3: String similarity (fallback)
        clean_query = re.sub(r'[^\w\s]', '', query).lower()
        clean_questions = [re.sub(r'[^\w\s]', '', q).lower() for q in self.faqs['Question']]
        str_similarities = [self.string_similarity(clean_query, q) for q in clean_questions]
        str_index = np.argmax(str_similarities)
        str_score = str_similarities[str_index]
        
        # Combine scores
        combined_scores = [
            0.6 * semantic_score + 
            0.3 * keyword_score +
            0.1 * str_score
            for i in range(len(self.faqs))
        ]
        
        best_index = np.argmax(combined_scores)
        best_score = combined_scores[best_index]
        
        # Determine method used
        methods = []
        if semantic_score > 0.3: methods.append("semantic")
        if keyword_score > 0.2: methods.append("keyword")
        if str_score > 0.5: methods.append("string")
        method = "+".join(methods) if methods else "fallback"
        
        return best_index, best_score, method
    
    def string_similarity(self, a, b):
        """Calculate normalized string similarity"""
        a = a.lower()
        b = b.lower()
        words_a = set(a.split())
        words_b = set(b.split())
        common = words_a & words_b
        return len(common) / (len(words_a) + len(words_b) - len(common) + 1e-9)
    
    def update_faq_usage(self, index):
        """Update usage statistics for a FAQ entry"""
        self.faqs.at[index, 'Use Count'] += 1
        self.faqs.at[index, 'Last Used'] = datetime.now()
        self.faqs.to_excel(self.faq_path, index=False)
    
    def log_conversation(self, user_input, response, matched_question, confidence, method):
        """Record conversation to Excel log"""
        new_entry = pd.DataFrame([{
            'Timestamp': datetime.now(),
            'User Input': user_input,
            'System Response': response,
            'Matched Question': matched_question,
            'Confidence': confidence,
            'Method': method
        }])
        
        # Append to existing log
        updated_log = pd.concat([self.logs, new_entry], ignore_index=True)
        updated_log.to_excel(self.log_path, index=False)
        self.logs = updated_log
    
    def add_contextual_response(self, answer, query):
        """Enhance answer with contextual elements using NLP"""
        doc = self.nlp(query)
        
        # Personalize with detected entities
        entities = [ent.text for ent in doc.ents if ent.label_ in ['PERSON', 'ORG', 'GPE']]
        if entities:
            name = entities[0]
            answer = answer.replace("you", name).replace("your", f"{name}'s")
        
        # Add follow-up based on question type
        question_types = {
            "how": "Would you like step-by-step instructions?",
            "why": "Would you like more details about the reasons?",
            "when": "Would you like calendar integration to set reminders?"
        }
        
        first_word = query.lower().split()[0] if query.split() else ""
        follow_up = question_types.get(first_word, "Can I help with anything else?")
        
        return f"{answer}\n\nFollow-up: {follow_up}"
    
    def analyze_query(self, query):
        """Perform advanced NLP analysis on query"""
        doc = self.nlp(query)
        analysis = {
            "tokens": [token.text for token in doc],
            "lemmas": [token.lemma_ for token in doc],
            "entities": [(ent.text, ent.label_) for ent in doc.ents],
            "sentiment": doc.sentiment,
            "keywords": [chunk.text for chunk in doc.noun_chunks]
        }
        return analysis
    
    def run(self):
        """Main interaction loop"""
        print("\n🧠 Advanced NLP-Powered FAQ System")
        print(f"📚 Knowledge base: {len(self.faqs)} questions loaded")
        print("Type 'analyze' for query insights, 'exit' to quit\n")
        
        while True:
            user_input = input("You: ").strip()
            if not user_input:
                continue
                
            if user_input.lower() == 'exit':
                print("\nThank you for using the FAQ system!")
                break
                
            if user_input.lower() == 'analyze':
                analysis = self.analyze_query(user_input)
                print("\n🔍 Query Analysis:")
                print(f"Tokens: {analysis['tokens']}")
                print(f"Lemmas: {analysis['lemmas']}")
                print(f"Entities: {analysis['entities']}")
                print(f"Keywords: {analysis['keywords']}")
                print(f"Sentiment: {analysis['sentiment']}")
                continue
                
            # Find best match
            best_index, confidence, method = self.find_best_match(user_input)
            
            if confidence > 0.4:
                faq = self.faqs.iloc[best_index]
                
                # Update usage stats
                self.update_faq_usage(best_index)
                
                # Enhance answer with contextual elements
                enhanced_answer = self.add_contextual_response(faq['Answer'], user_input)
                
                # Format response
                response = (
                    f"🤖 [Confidence: {confidence:.0%} | Method: {method}]\n"
                    f"Q: {faq['Question']}\n"
                    f"A: {enhanced_answer}"
                )
                print(f"\n{response}")
                
                # Log conversation
                self.log_conversation(
                    user_input, 
                    response, 
                    faq['Question'], 
                    confidence,
                    method
                )
            else:
                # NLP-based fallback response
                doc = self.nlp(user_input)
                root_verb = next((token.lemma_ for token in doc if token.pos_ == "VERB"), "assist")
                subject = next((token.text for token in doc if token.dep_ == "nsubj"), "that")
                
                response = (
                    f"🤖 I'm not certain about {subject}, but I can {root_verb} with:\n"
                    f"• Account questions\n"
                    f"• Order information\n"
                    f"• Technical support\n"
                    f"Try rephrasing or ask about one of these topics!"
                )
                print(f"\n{response}")
                self.log_conversation(user_input, response, None, confidence, "fallback")


if __name__ == "__main__":
    # Get file paths from user or use defaults
    faq_path = input("Enter FAQ file path (default: faq_knowledge.xlsx): ").strip() or "faq_knowledge.xlsx"
    log_path = input("Enter log file path (default: conversation_log.xlsx): ").strip() or "conversation_log.xlsx"
    
    # Initialize and run system
    faq_system = AdvancedFAQSystem(faq_path, log_path)
    faq_system.run()